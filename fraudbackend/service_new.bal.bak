import ballerina/http;
import ballerina/io;
import ballerina/mime;
import ballerina/os;
import ballerina/log;
import ballerina/lang.'string as strings;
import ballerina/system;
import ballerina/encoding;
import ballerina/io;          // Instead of 'system'
import ballerina/mime;        // For base64 operations (encoding)
import ballerina/file;        // For temporary file handling

// Define API endpoints
configurable string mlScriptPath = ?;
configurable boolean useOcrApi = true;
configurable boolean useCloudOcr = false;
configurable string ocrApiKey = "";
configurable string ocrScriptPath = "../fraudML/extract_text.py";

// Google Cloud Vision API
final http:Client visionApiClient = check new("https://vision.googleapis.com/v1");

// Define request/response types
type JobPostingRequest record {
    string title;
    string description;
    string? imageData;
};

type FraudResponse record {
    boolean isFraud;
    decimal confidenceScore;
    string message;
};

// Google Cloud Vision API Request Types
type ImageSource record {
    string imageUri?;
    string gcsImageUri?;
};

type Image record {
    string content?;
    ImageSource source?;
};

type Feature record {
    string type;
    int maxResults?;
    string model?;
};

type VisionRequest record {
    Image image;
    Feature[] features;
    string imageContext?;
};

type VisionApiRequest record {
    VisionRequest[] requests;
};

// Google Cloud Vision API Response Types
type TextAnnotation record {
    string locale?;
    string description;
    string[] boundingPoly?;
};

type AnnotateImageResponse record {
    TextAnnotation[] textAnnotations?;
    record {} error?;
};

type VisionApiResponse record {
    AnnotateImageResponse[] responses;
};

service / on new http:Listener(9090) {
    // Enable CORS for frontend communication
    resource function get health() returns string {
        return "Fraud detection service is running";
    }

    // Endpoint to check job posting for fraud
    @http:ResourceConfig {
        cors: {
            allowOrigins: ["http://localhost:3000"],
            allowCredentials: true,
            allowHeaders: ["*"],
            allowMethods: ["POST", "OPTIONS"]
        }
    }
    resource function post checkFraud(@http:Payload JobPostingRequest posting) returns FraudResponse|error {
        log:printInfo("Received request to check fraud for job posting: " + posting.title);
        
        // Prepare data for ML model
        string title = posting.title;
        string description = posting.description;
        
        // Call Python ML model
        FraudResponse response = check callMLModel(title, description);
        
        return response;
    }
    
    // Endpoint to handle image upload and text extraction
    @http:ResourceConfig {
        cors: {
            allowOrigins: ["http://localhost:3000"],
            allowCredentials: true,
            allowHeaders: ["*"],
            allowMethods: ["POST", "OPTIONS"]
        }
    }
    resource function post extractText(http:Request request) returns json|error {
        var parts = check request.getBodyParts();
        string extractedText = "";
        
        foreach var part in parts {
            if (part.getContentDisposition().name == "image") {
                byte[] bytes = check part.getByteArray();
                // Here you would implement OCR or call an external OCR service
                io:println("Received image of size: " + bytes.length().toString() + " bytes");
                extractedText = check extractTextFromImage(bytes);
            }
        }
        
        return { text: extractedText };
    }
}

// Function to call Python ML model
function callMLModel(string title, string description) returns FraudResponse|error {
    // Create a temporary file with the job data
    string tempFilePath = system:getTemporaryFolderPath() + "/job_data.txt";
    string jobData = title + "\n" + description;
    check io:fileWriteString(tempFilePath, jobData);
    
    log:printInfo("Calling ML model with job data: " + title);

    // Prepare the command for Python script execution
    os:Process|error execResult = os:exec({
        value: "python",
        arguments: [mlScriptPath, tempFilePath]
    });
    
    if (execResult is error) {
        log:printError("Failed to execute ML script: " + execResult.message());
        return error("Failed to process job posting");
    }
    
    os:Process process = execResult;
    int exitCode = check process.waitForExit();
    
    // Read output from the process
    string result = "";
    var outputResult = process.output();
    
    if (outputResult is io:ReadableByteChannel) {
        io:ReadableCharacterChannel characterChannel = new io:ReadableCharacterChannel(outputResult, "UTF-8");
        
        // Read line by line
        string? readLine = "";
        while (true) {
            readLine = check characterChannel.read(1024);
            if (readLine is string) {
                if (readLine != "") {
                    result = result + readLine;
                }
            } else {
                break;
            }
        }
        
        check characterChannel.close();
    }
    
    log:printInfo("ML model returned: " + result + " with exit code: " + exitCode.toString());
    
    if (exitCode != 0) {
        return error("ML model execution failed");
    }
    
    // Parse the result (0 = real, 1 = fraud)
    boolean isFraud = strings:trim(result) == "1";
    
    return {
        isFraud: isFraud,
        confidenceScore: isFraud ? 0.85 : 0.98, // Using values from model_evaluation.txt
        message: isFraud ? 
            "This job posting has characteristics similar to fraudulent posts." : 
            "This job posting appears to be legitimate."
    };
}

// Function to extract text from image using OCR
function extractTextFromImage(byte[] imageData) returns string|error {
    if (!useOcrApi) {
        return "OCR is currently disabled. Please enter job details manually or enable OCR in the backend configuration.";
    }
    
    if (useCloudOcr && ocrApiKey != "") {
        // Use Google Cloud Vision API
        return extractTextUsingGoogleVision(imageData);
    } else {
        // Use local Tesseract OCR through Python script
        // Save the image to a temporary file
        string tempImagePath = system:getTemporaryFolderPath() + "/temp_image.jpg";
        check io:fileWriteBytes(tempImagePath, imageData);
        
        log:printInfo("Running OCR on image saved at: " + tempImagePath);
        
        // Call the Python OCR script
        os:Process|error execResult = os:exec({
            value: "python",
            arguments: [ocrScriptPath, tempImagePath]
        });
        
        if (execResult is error) {
            log:printError("Failed to execute OCR script: " + execResult.message());
            return "Failed to extract text from image. Make sure Tesseract OCR is installed and Python dependencies are set up.";
        }
        
        os:Process process = execResult;
        int exitCode = check process.waitForExit();
        
        // Read output from the process
        string extractedText = "";
        var outputResult = process.output();
        
        if (outputResult is io:ReadableByteChannel) {
            io:ReadableCharacterChannel characterChannel = new io:ReadableCharacterChannel(outputResult, "UTF-8");
            
            // Read line by line
            string? readLine = "";
            while (true) {
                readLine = check characterChannel.read(1024);
                if (readLine is string) {
                    if (readLine != "") {
                        extractedText = extractedText + readLine;
                    }
                } else {
                    break;
                }
            }
            
            check characterChannel.close();
        }
        
        // Clean up temporary file
        os:Process|error rmResult = os:exec({
            value: "del",
            arguments: [tempImagePath]
        });
        
        return extractedText;
    }
}

// Function to call Google Cloud Vision API for OCR
function extractTextUsingGoogleVision(byte[] imageData) returns string|error {
    // Convert image bytes to base64
    string base64Image = encoding:encodeBase64(imageData);
    
    // Prepare the request payload
    VisionApiRequest payload = {
        requests: [
            {
                image: {
                    content: base64Image
                },
                features: [
                    {
                        type: "TEXT_DETECTION",
                        maxResults: 1
                    }
                ]
            }
        ]
    };
    
    // Send request to Google Cloud Vision API
    http:Response response = check visionApiClient->post("/images:annotate?key=" + ocrApiKey, payload);
    
    if (response.statusCode == 200) {
        VisionApiResponse apiResponse = check response.getJsonPayload().cloneWithType(VisionApiResponse);
        
        if (apiResponse.responses.length() > 0) {
            AnnotateImageResponse firstResponse = apiResponse.responses[0];
            
            if (firstResponse.textAnnotations is TextAnnotation[] && firstResponse.textAnnotations.length() > 0) {
                // The first annotation contains the entire text from the image
                TextAnnotation[] annotations = <TextAnnotation[]>firstResponse.textAnnotations;
                if (annotations.length() > 0) {
                    return annotations[0].description;
                }
            }
        }
        
        return "No text found in the image.";
    } else {
        map<json> errorPayload = check response.getJsonPayload();
        string errorMessage = errorPayload.toString();
        log:printError("Google Vision API error: " + errorMessage);
        return "Error processing image: " + errorMessage;
    }
}
